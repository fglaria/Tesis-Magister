\chapter{RESULTADOS}\label{chap:contributions}
\vskip 3.0ex

En esta sección se presentan las características de los grafos $G(V, E)$ y de la estructura compacta utilizada para evaluar la propuesta, y luego se compara tanto el nivel de compresión como los tiempos de acceso secuencial y aleatorio de los algoritmos propuestos contra otros algoritmos relevantes del área.

Los algoritmos a comparar son actuales en el estado del arte para compresión de grafos, incluyendo la última versión de WebGraph \cite{boldi2011layered}, Apostolico and Drovandi \cite{apostolico2009graph}, y k2tree \cite{brisaboa2014compact}.

Todas las pruebas y experimentos se realizaron en una computadora con un procesador Intel i7 2.70GHz CPU con 12GB de RAM, y los algoritmos fueron implementados con el compilador g++ 8.2.1 con la opción de optimización O3.

\section{Grafos}
Para evaluar el rendimiento del método propuesto y comparar los resultados con el estado del arte, se seleccionan 8 grafos no densos y no dirigidos, ya que el método apunta a lograr una mejor compresión para grafos con estas características. Los 8 grafos son los siguientes:

\begin{itemize}
	\item \texttt{dblp-2010} y \texttt{dblp-2011} de WebGraph\footnote{\url{http://law.di.unimi.it/datasets.php}}.
	\item \texttt{snap-dblp} y \texttt{snap-amazon} de SNAP\footnote{\url{https://snap.stanford.edu/data/}}.
	\item \texttt{marknewman-astro} y \texttt{marknewman-condmat} de Quick-Cliques\footnote{\url{http://www.dcs.gla.ac.uk/~pat/jchoco/clique/enumeration/quick-cliques/doc/}}.
	\item \texttt{coPapersDBLP} junto a \texttt{coPapersCiteseer} de Network repository\footnote{\url{http://networkrepository.com/}}.
\end{itemize}

En la \autoref{table:gafros3} se muestran la cantidad de vértices (\boldsymbol{$|V|$}), aristas (\boldsymbol{$|E|$}), cliques maximales (\boldsymbol{$|\mathcal{C}|$}), grado medio (\boldsymbol{$\overline{d}$}) y máximo (\boldsymbol{$d_{max}$}) de los vértices de los grafos, valor de degeneracy (\boldsymbol{$D(G)$}), coeficiente de clusterización (\boldsymbol{$C(G)$}) y transitividad (\boldsymbol{$T(G)$}). De ella se pueden apreciar varias características importantes de los grafos.

En cuanto a tamaño, \texttt{marknewman-astro} y \texttt{marknewman-condmat} son los más pequeños, no superan los 50.000 vértices. Los demás tienen un tamaño bastante similar, siendo \texttt{dblp-2011} el más grande con 986.324 vértices.

Con respecto al número de aristas, \texttt{marknewman-astro} y \texttt{marknewman-condmat} también son los menores con menos de 400.000, luego \texttt{dblp-2010}, \texttt{dblp-2011}, \texttt{snap-dblp} y \texttt{snap-amazon} entre 1 y 7 millones, y finalmente \texttt{coPapersDBLP} junto a \texttt{coPapersCiteseer} con más de 30 millones de aristas.

En cantidad de cliques maximales, la mayoría tiene una cantidad proporcional a su número de vértices, a excepción de tres grafos: \texttt{snap-amazon} posee más del doble de cliques que vértices, y tanto \texttt{coPapersDBLP} y \texttt{coPapersCiteseer} tienen menos de la mitad de cliques que vértices. Esto quiere decir que su clusterización es distinta a los demás, lo que se confirma estudiando los indicadores restantes.

Con respecto al grado medio y máximo de los vértices en los grafos, se destacan \texttt{snap-dblp} con 6,62 de media pero 2.752 de máxima, que contrasta con \texttt{dblp-2011} que tiene cerca del triple de vértices, aristas y cliques, pero una media similar y un grado máximo tres veces menor. Y \texttt{coPapersDBLP} con \texttt{coPapersCiteseer} que presentan 56,41 y 73,88 de grado medio, y 3.299 con 1.188 de grado máximo, respectivamente.

Finalmente en los indicadores de clusterización, los mismos grafos \texttt{coPapersDBLP} y \texttt{coPapersCiteseer} presentan los valores más altos, lo que podría dar un indicio que los resultados de compresión y tiempos de acceso serán distintos a los demás. 


\input{tables/grafos3}

La distribución del grado de los vértices para cada grafo se presenta en la \autoref{fig:grades}. Se puede apreciar que todos los grafos presentan una distribución similar, donde muchos vértices tienen pocos vecinos, y pocos vértices tienen muchos vecinos.

\input{figs/grades}
\input{figs/cliqueDist2}

La distribución de los tamaños de los cliques maximales para cada grafo se muestra en la \autoref{fig:cliqueDist2}. Es importante notar que el gráfico del grafo \texttt{coPapersCiteseer} está truncado para efectos de comparación, pero tiene muy pocos cliques maximales por sobre el límite fijado gráficamente. Además, el grafo \texttt{snap-amazon} posee la mayor cantidad de cliques maximales pequeños.

La mayoría de los grafos contienen muchos cliques con menos de 50 vértices, a excepción de los grafos \texttt{snap-amazon}, \texttt{coPapersDBLP} y \texttt{coPapersCiteseer}. El primero contiene solo cliques pequeños, de no más de 20 vértices. Los otros dos grafos contienen una cantidad considerable de cliques de hasta 100 vértices. Esto permitirá contrastar los resultados del método propuesto entre grafos con distintas cantidades de cliques maximales grandes.



\section{Estructura compacta}

Para generar la estructura compacta se usa \texttt{SDSL}\footnote{\url{https://github.com/simongog/sdsl-lite}} desarrollada por Gog et al.\cite{gbmp2014sea}, y se implementó Huffman con acceso aleatorio \cite{huffman1952method}. Las estructuras de datos sucintas a evaluar dependen del tipo de secuencia a compactar.

\begin{itemize}
	\item Para las secuencias de símbolos, se consideran las estructuras basadas en wavelet matrix (\textit{wm}) \cite{claude2015wavelet} y wavelet tree (\textit{wt}) \cite{grossi2003high}.
	\item Para la secuencia de bits, se consideran las estructuras basadas en bitmaps comprimidos de Raman, Raman y Rao (\textit{rrr}) \cite{raman2002succinct}, y Okanohara y Sadakane (\textit{sdb}) \cite{DBLP:journals/corr/abs-cs-0610001}.
\end{itemize}

La secuencia de bytes $BB$ se comprime usando código Huffman\cite{huffman1952method}. Esto significa que $BB$ se transforma en una secuencia de bits, lo que requiere actualizar los índices de inicio de sus particiones en la secuencia $Y$, para poder obtener la secuencia de bytes equivalentes, de acuerdo a un desplazamiento en $BB$. Esto también conlleva que, por cada consulta a una partición, primero hay que decodificar todos los bytes correspondientes de esa partición antes de poder usarlos para detectar si los nodos asociados son vecinos o no. Esta codificación se implementó, ya que no es parte de la librería SDSL.

%\textcolor{red}{Creo suficiente no entrar más en detalle sobre este cambio, debido a que no es muy complejo.}

Como factores de selección, se consideran el nivel de compresión en bits, y tanto el tiempo de reconstrucción secuencial usando el Algoritmo~\ref{alg:sequential}, como el tiempo de acceso aleatorio al recuperar los vecinos de un millón de nodos, usando el Algoritmo~\ref{alg:neighbors}, para cada grafo y cada función de ranking con cada una de las estructuras antes planteadas.

%\textcolor{red}{Aquí antes mostraba las tablas con los tamaños en bytes de cada estructura compacta. Las eliminé, ya que creo no aportan en mucho comparado con la comparativa entre BPE y espacio.}

Para ello, se decide construir la estructura compacta para cada grafo y cada función de ranking, con todas las posibles combinaciones para las secuencias. En la \autoref{fig:sdslBPE2}, \autoref{fig:sdslBPE3}, \autoref{fig:sdslBPE4}, y \autoref{fig:sdslBPE5}, se compara para cada grafo el BPE de las ocho posibles combinaciones para cada función de ranking con respecto al tiempo secuencial de reconstrucción del grafo. Y en la \autoref{fig:sdslBPEAle2}, \autoref{fig:sdslBPEAle3}, \autoref{fig:sdslBPEAle4} y \autoref{fig:sdslBPEAle5}, el BPE con respecto al tiempo de acceso aleatorio al recuperar los vecinos de un millón de nodos.

%\textcolor{red}{No estoy seguro que esta sea la mejor manera de anotar tantas figuras.}

En la mayoría de los casos, la estructura que presenta la mejor relación entre BPE y tiempos es la de secuencias de símbolos con \textit{wm}, secuencia de bytes con \textit{hutu}, y secuencia de bits con \textit{sdb}.  Las opciones que presentan menores tiempos aumentan en BPE, y viceversa. Por tanto, se elige esta combinación de estructuras de secuencias como la estructura compacta a desarrollar.

\input{figs/sdslBPEAle2}
\input{figs/sdslBPEAle3}
\input{figs/sdslBPEAle4}
\input{figs/sdslBPEAle5}
\input{figs/sdslBPE2}
\input{figs/sdslBPE3}
\input{figs/sdslBPE4}
\input{figs/sdslBPE5}


\section{Comparación de funciones de ranking}

A continuación se comparan las estructuras compactas resultantes, usando las tres funciones de ranking basadas en la frecuencia del vértice en los cliques maximales $r_{f}(u)$, en la cantidad de vecinos en los cliques del vértice $r_{c}(u)$, y la razón entre ambas funciones $r_{r}(u)$. 

En la \autoref{fig:bpe3} y la \autoref{table:bpe3} se muestran los BPE de las estructuras compactas finales, aplicando las funciones de ranking en la heurística de clusterización. Se puede apreciar que $r_{f}(u)$ logra los mejores resultados de compresión, con excepción del grafo \texttt{snap-amazon} donde $r_{r}(u)$ tiene un BPE levemente menor. Si este parámetro fuera el único a considerar para elegir la mejor función, $r_{f}(u)$ sería la mejor opción, pero es necesario profundizar en la conformación de la estructura.

\input{figs/bpe3}
\input{tables/bpe3}

En la \autoref{fig:nPartitions} se presentan la cantidad de particiones que contiene las estructuras compactas para cada función de ranking. Se aprecia con bastante claridad que la función $r_{r}(u)$ genera más particiones que las otras dos, y dado que el BPE expuesto en la \autoref{fig:bpe3} no refleja esta diferencia, se puede intuir que las particiones son más pequeñas. Para profundizar en este punto, se estudiará la composición de las secuencias de las estructuras compactas para cada función de ranking.

\input{figs/nPartitions}

En la \autoref{fig:proportionBits}(a) se ilustra la proporción de bits para cada secuencia dentro de la estructura compacta, para cada función de ranking. En la \autoref{fig:proportionBits}(b) se ilustra la misma proporción normalizada. Como se puede observar, la secuencia que más aporta para todos los casos es la de vértices \textit{X}, seguida de la secuencia de bytes \textit{BB}, luego \textit{Y} y finalmente la secuencia de bits \textit{B}. Nuevamente las funciones de ranking $r_{f}(u)$ y $r_{c}(u)$ tienen resultados similares, y para la función $r_{r}(u)$ la secuencia \textit{X} aumenta su proporción mientras que \textit{BB} disminuye. Esto seguramente afectará positivamente el tiempo de respuesta de los algoritmos propuestos, ya que todos requieren comparar los bytes de \textit{BB} de cada partición entre ellos, y si hay menos bytes requerirá menos tiempo.

\input{figs/bitsProp}

Para estudiar la composición de las particiones para cada función de ranking, en la \autoref{fig:maxNodes} se ilustran la cantidad máxima de vértices en la secuencia \textit{X} por partición, y en la \autoref{fig:maxBytes} la cantidad máxima de bytes por vértice en la secuencia \textit{BB} de las estructuras compactas resultantes. Como se puede apreciar, la función $r_{r}(u)$ presenta consistentemente los menores valores entre las tres funciones, lo que permite asegurar que es la que mejor agrupa y usa el espacio de las particiones en la estructura compacta.

\input{figs/maxNodes}
\input{figs/maxBytes}

En la \autoref{fig:cdfBPN} se puede estudiar la función de distribución acumulativa (CDF) para la cantidad de bytes por vértice en la estructura compacta, para cada función de ranking. Se confirma que para la función $r_{r}(u)$ las particiones contienen menos bytes en la secuencia \textit{BB}, ya que la cantidad de bytes por vértice es significativamente menor.

\input{figs/cdf}


En la \autoref{fig:timesRanking} se ven los tiempos de acceso aleatorio para la obtención de vecinos de cualquier vértice $u \in G(V, E)$ desde las estructuras compactas generadas con las tres funciones de ranking en comparación. Como se esperaba, los tiempos menores se obtienen usando la estructura basada en la función $r_{r}(u)$, ya que no tiene que comparar tantos bytes por particiones como las otras dos.

\input{figs/timesRanking}

Entonces, considerando la gran ventaja en tiempo de acceso y la leve diferencia en compresión, se concluye que la mejor alternativa entre las tres funciones de ranking es $r_{r}(u)$. 

En la \autoref{table:constructTimes} se muestran los tiempos en segundos de la generación del listado de cliques maximales $\mathcal{C}$ ($t_{\mathcal{C}}$) directo del grafo, el tiempo de generar la estructura compacta desde el listado de cliques ($t_{CS}$), el tiempo total de generar la estructura compacta ($t_{T} = t_{\mathcal{C}} + t_{CS}$) y el tiempo para recuperar el listado de cliques $\mathcal{C}$ desde la estructura compacta ($t'_{\mathcal{C}})$) usando el Algoritmo~\ref{alg:cliques}. 

Se debe notar que el tiempo para recuperar el listado de cliques desde la estructura compacta es menor al requerido desde el grafo directamente. Si bien se puede argumentar que para llegar a la estructura compacta se debe generar el listado desde el grafo, por tanto $t_{\mathcal{C}}$ es necesario pagarlo ineludiblemente, una vez generada la estructura se puede obtener $\mathcal{C}$ de ella, en menor tiempo y sin tener que descomprimir el grafo. Se destaca este contraste en los grafos \texttt{coPapersDBLP} y \texttt{coPapersCiteseer}, donde desde la estructura compacta es sobre 10 veces más rápida.

\input{tables/constructTimes}

A continuación se procede a comparar la opción de compresión seleccionada con los algoritmos del estado del arte ya mencionados.




\section{Comparando con estado del arte}
En esta sección se compara el nivel de compresión y los tiempos de acceso de la estructura compacta usando la función de ranking $r_{r}(u)$ seleccionada en la sección anterior, con los algoritmos más recientes de WebGraph \cite{boldi2011layered}, Apostolico and Drovandi (AD) \cite{apostolico2009graph}, y k2tree \cite{brisaboa2009k, brisaboa2014compact}.

A continuación se detallan las notaciones a usar en el resto de la sección.

\begin{itemize}
	\item Para la estructura compacta propuesta, basada en las superposición de cliques maximales, se diferencian dos casos:
		\begin{itemize}
			\item $C_{rf}$: Usando la estructura con función de ranking $r_{f}(u)$.
			\item $C_{rr}$: Usando la estructura con función de ranking $r_{r}(u)$.
		\end{itemize}			
	\item En el caso de Webgraph, como el algoritmo genera una estructura adicional para el caso de acceso aleatorio, se diferencian dos casos: 
		\begin{itemize}
			\item $WG_{s}$: Para el caso de acceso secuencial. 
			\item $WG_{a}$: Para el caso de acceso aleatorio.
		\end{itemize}
	\item Para el caso de k2tree, se diferencian dos casos:
		\begin{itemize}
			\item $k2T$: Cuando el algoritmo usa el orden del grafo original.
			\item $k2T_{BFS}$: Cuando el algoritmo usa el orden por BFS.
		\end{itemize}			
	\item $AD$: El algoritmo BFS de Apostolico y Drovandi.
\end{itemize}

Es importante recordar que los algoritmos Webgraph y AD están orientados a comprimir grafos dirigidos. Esto requiere que cada arco de los grafos no dirigidos a evaluar deben ser anotados en ambos sentidos antes de ser comprimidos. 

Mención especial requiere k2-tree, donde la autora proporcionó una versión mejorada del algoritmo orientado específicamente a grafos no dirigidos, que reduce el espacio necesario para representar el grafo considerando la mitad de la matriz de adyacencia, junto con la capacidad de dicho modelo de entregar los listados de vecinos directos como reversos. Para obtener el listado de adyacencia de un nodo, se debe obtener ambos listados y retornar su unión.

Con esto presente, en la \autoref{table:BPEcomp} se comparan los BPE de todos los casos, resaltando los mejores resultados. Para dos de los grafos comprimidos, \texttt{marknewman-astro} y \texttt{coPapersDBLP}, la propuesta usando la función de ranking $r_{f}(u)$ es la que obtiene el menor resultado, seguido muy de cerca por la versión usando la función de ranking $r_{r}(u)$. Para \texttt{marknewman-condmat} también logra el mejor resultado, pero seguido por k2tree con BFS. Con el grafo \texttt{coPapersCiteseer} se obtiene un resultado muy cercano al mejor caso de k2tree con BFS, y en los demás, los dos mejores resultados los obtienen alguna de las dos versiones de k2-tree, seguido siempre por alguna de las dos opciones del método propuesto. Tanto Webgraph como AD no logran competir en compresión con los demás.

Esto confirma que la propuesta es competitiva con el estado del arte, solo considerando el nivel de compresión. A continuación se evalúa el rendimiento en tiempos de acceso.

\input{tables/bpeSmall}

Para comparar el tiempo de acceso aleatorio, se prueba el Algoritmo~\ref{alg:neighbors} recuperando los vecinos de un millón de vértices aleatorios de $G(V, E)$, y se divide el tiempo que demora dicha solicitud por la cantidad de aristas recuperadas. En la \autoref{table:timesRandom} se presentan los resultados, sin considerar el caso de Webgraph secuencial ($WG_{s}$), ya que solo se considera acceso aleatorio. 

Como se puede apreciar, Webgraph presenta los menores tiempos de acceso entre todos los algoritmos, y AD lo sigue siempre en segundo lugar. Luego para los grafos \texttt{dblp-2010}, \texttt{dblp-2011}, \texttt{snap-dblp} y \texttt{snap-amazon}, el método propuesto logra mejores resultados que ambas versiones de k2-tree, con especial atención a \texttt{dblp-2011} donde logra ser el doble de rápido. Para el resto de los casos, el resultado es bastante competitivo entre esos métodos.

\input{tables/timesRandom}

El tiempo de reconstrucción secuencial se midió usando el Algoritmo~\ref{alg:sequential}. En la \autoref{table:timesSecuencial} se presentan los resultados obtenidos para los algoritmos evaluados. En este caso, si bien el método propuesto es más lento que los demás, para casos como \texttt{marknweman-astro}, \texttt{marknewman-condmat}, \texttt{dblp-2010} y \texttt{snap-dblp}, la diferencia es menor a un segundo. Para el resto de los casos, los grafos tienen una cantidad considerable de arcos, \texttt{dblp-2011} y \texttt{snap-amazon} tienen la mayor cantidad de cliques, y \texttt{coPapersDBLP} con \texttt{coPapersCiteseer} tienen muchos cliques de hasta 100 vértices, y presentan una relación no proporcional entre cantidad de vértices y cantidad de cliques, como lo muestra la \autoref{table:gafros3}, lo que afecta bastante a la hora de recuperar dichos grafos.

Para evaluar mejor la competitividad, en las Figuras~\ref{fig:bpetAle1}~-~\ref{fig:bpetAle4} se muestras los BPE con respecto a los tiempo de acceso aleatorio en micro-segundos, y en las Figuras~\ref{fig:bpetSec1}~-~\ref{fig:bpetSec4} los BPE con respecto a los tiempos de reconstrucción secuencial en segundos, obtenidos para cada algoritmo y cada grafo.

Se puede apreciar que, para el caso aleatorio, si bien el método de compresión se ubica casi siempre en el cuadrante de menor BPE y mayor tiempo, otros logran una ubicación de menor calidad, como los casos de los algoritmos de k2tree para los grafos \texttt{dblp-2010}, \texttt{dbpl-2011} en la \autoref{fig:bpetAle2}, y \texttt{snap-dblp} en la \autoref{fig:bpetAle3}. En el caso secuencial, para el set de grafos pequeños \texttt{marknewman-astro} y \texttt{marknewman-condmat}, se logra muy buena ubicación en el cuadrante de menor BPE y menor tiempo (\autoref{fig:bpetSec1}), pero para los demás grafos el tiempo es muy lejano a los demás algoritmos. 

En cuanto a verificar si dos nodos son vecinos o no, la estructura planteada es la única que tiene dicha consulta implementada y no requiere descomprimir para responder directamente. Tanto Webgraph como AD, al usar diferencias para codificar los listados de adyacencia, primero requieren obtener el listado de vecinos de un nodo y luego revisar si el segundo nodo pertenece o no a dicha lista. La propuesta de k2tree podría responder dicha consulta, ya que codifica la matriz de adyacencia de tal manera que podría revisar directamente la vecindad de dos nodos, pero no la tiene implementada.

\input{tables/timesSecuencial} 

\input{figs/bpetAle1}
\input{figs/bpetAle2}
\input{figs/bpetAle3}
\input{figs/bpetAle4}

\input{figs/bpetSec1}
\input{figs/bpetSec2}
\input{figs/bpetSec3}
\input{figs/bpetSec4}
