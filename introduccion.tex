\chapter{INTRODUCCI\'ON}\label{chap:intro}
\vskip 3.0ex

%\textcolor{red}{Todavía no he cambiado nada.}

En los últimos años se ha visto un gran crecimiento en grafos de redes sociales y de la web. Por ejemplo, el número de sitios indexados por los principales motores de búsqueda en la web se estima actualmente en al menos 5,68 miles de millones\footnote{\url{http://www.worldwidewebsize.com/}, consultado el 07 de agosto del 2019.}, o la cantidad de usuarios activos diarios en redes sociales, como Facebook\footnote{\href{https://investor.fb.com/investor-news/press-release-details/2019/Facebook-Reports-First-Quarter-2019-Results/default.aspx}{https://investor.fb.com}, informe de resultados del primer trimestre del 2019 de Facebook.} con 1,56 mil millones y un crecimiento anual de un 8$\%$, o Instagram\footnote{\url{https://instagram-press.com/our-story/}, Infocenter de Instagram.} con más de mil millones de usuarios y más de 500 millones de historias diarias.

El grafo de la web representa los enlaces que tiene cada sitio hacia otro, y se modela como un grafo dirigido, con un nodo por cada sitio anexado y un arco dirigido por cada enlace que apunte a otro sitio. Los grafos de redes sociales representan relaciones entre entidades, como personas o empresas, y son modelados como grafos dirigidos o no dirigidos según corresponda. Por ejemplo, Twitter e Instagram permiten a sus usuarios seguir a otros, conectándolos de manera asimétrica, y sus representaciones corresponden a un grafo dirigido, mientras Facebook conecta de manera simétrica a sus usuarios, por tanto se representa como un grafo no dirigido.

La estructura de enlaces del grafo de la web es usada por algoritmos de ranking como \textit{PageRank} \cite{page1999pagerank}, \textit{HITS} \cite{kleinberg1999authoritative}, y \textit{Positional Power Function} \cite{herings2001measuring, herings2005positional}, como también para la detección de comunidades \cite{kumar1999trawling, flake2002self, sozio2010community}, detección de SPAM \cite{castillo2007know, becchetti2008link, saito2007large}, detección de anomalías \cite{papadimitriou2010web}, además de servir para estudiar la web y su evolución \cite{donato2005mining, kolari2004web, dourisboure2007extraction}. Los grafos de redes sociales son estudiados para reconocer actores relevantes en comunidades \cite{saito2012efficient, chen2013identifying}, identificar difundidores eficientes \cite{kitsak2010identification, lappas2010finding, zhou2014maximizing}, desarrollar algoritmos para la maximización de influencia \cite{chen2012efficient}, y estudiar cómo se propaga la información \cite{mislove2007measurement, cha2009measurement, ye2010measuring, bakshy2012role, chen2013information}.

El gran tamaño de estos grafos trae consigo grandes problemas de procesamiento. Su gran cantidad de vértices y aristas hacen prácticamente imposible mantener en memoria toda esa información, sobre mil millones de nodos y todas las conexiones entre ellos. Y procesar consultas sobre dichos grafos es muy costoso, sobre todo cuando la jerarquía de memoria de los sistemas computacionales modernos penaliza los tiempos de acceso a medida que los datos se alejan de las unidades de procesamiento.

Estos problemas han motivado a la comunidad científica a proponer estructuras comprimidas que permitan la navegación del grafo a través de consultas básicas, como obtener el listado de vecinos de un nodo. El objetivo de estas representaciones comprimidas es permitir la simulación de algoritmos de procesamiento de grafos usando mucho menos espacio en memoria que las representaciones sin comprimir.

Por otra parte, la detección de cliques maximales en grafos es un problema NP-Hard \cite{karp1972reducibility}, y existen varios enfoques para tratar el problema \cite{bron1973algorithm, eblen2012maximum, hendrix2010theoretical, bomze1999maximum, eppstein2010listing, eppstein2011listing}. Esto es particularmente de interés en grafos de red social para detectar comunidades \cite{modani2008large}, donde es provechoso contar con modelos comprimidos de dichos grafos, y que permitan obtener el listado de cliques maximales de manera rápida.

En el contexto de estructuras de datos sucintos, actualmente existen estructuras compactas que permiten representar secuencias de bits, bytes y símbolos, con soporte de consultas básicas y rápidas \cite{raman2002succinct, grossi2003high, claude2015wavelet}.

Este método primero enumera los cliques maximales y luego los representa en una estructura compacta. El esquema propuesto aprovecha tanto el tamaño como la superposición de vértices en los cliques con el objetivo de reducir el número de vértices explícitamente representados en la estructura. Los resultados muestran alto nivel de compresión y tiempos de acceso competitivo en grafos reales con un alto coeficiente de clustering y con tamaños de cliques medianos o grandes.

%En este trabajo, se propone un método de compresión de grafos poco densos y no dirigidos, que aprovecha la cantidad de vértices en común de sus cliques maximales, para crear una estructura compacta que permita responder consultas de manera eficiente. Se decide aprovechar la superposición de vértices entre cliques maximales, mientras más clusterizados sean los grafos a comprimir, es esperable que dicha superposición sea más provechosa de codificar de manera alternativa y eficiente.

%En este trabajo, se propone un método de compresión de grafos poco densos y no dirigidos, que aprovecha la cantidad de vértices en común de sus cliques maximales, para crear una estructura compacta que permita responder consultas de manera eficiente.





