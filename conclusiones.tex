\chapter{CONCLUSIONES}\label{chap:conclusion}
\vskip 3.0ex

%En progreso...
\textcolor{red}{En proceso...}

Este trabajo se logra desarrollar un método de compresión de grafos no dirigidos y poco densos, basado en clustering de cliques maximales, y usando estructuras de datos sucintos. Se logra llegar a una representación comprimida de un grafo que permite responder consultas usuales como listado de vecinos de un nodo y reconstrucción del grafo, y otras consultas no tan usuales como obtener el listado de cliques maximales o saber si dos nodos son vecinos, todo sin tener que descomprimir el grafo..

El nivel de compresión, medido en BPE, es bastante competitivo al estado del arte, siendo superado solo por las dos versiones evaluadas de k2tree, ambas contando con una reciente mejora realizada directamente por la autora para representar grafos no dirigidos. Comparado con los otros algoritmos, el resultado en compresión es bastante mejor, sobre todo comparado con WebGraph. Los mejores BPE se logran con grafos muy clusterizados y cliques de muchos nodos, como \texttt{coPapersDBLP} (0,78) y \texttt{coPapersCiteseer} (0,52).
%superando en todos los casos estudiados a los otros algoritmos. Incluso puntualmente para el caso de los grafos \texttt{coPapersDBLP} y \texttt{coPapersCiteseer}, los cuales poseen los coeficiente de clusterización (0,80 y 0,83) y transitividad (0,65 y 0,77) más altos (ver Tabla~\ref{table:gafros3}, se logran los BPE de 0,80 y 0,52 respectivamente, lo que es muy eficiente. Si bien este resultado en la compresión es muy positivo, es necesario reconocer el efecto que conlleva en los tiempos de acceso 

El tiempo de acceso aleatorio, medido recuperando vecinos para un millón de nodos, en varios casos se logran mejores resultados que ambos algoritmos de k2tree, pero no comparado con BFS y menos con WebGraph, que mantiene total predominancia en este ámbito. En tiempo de reconstrucción secuencial del grafo, el algoritmo propuesto se mantiene competitivo para la mayoría de los grafos, a excepción de los grafos \texttt{snap-amazon}, \texttt{coPapersDBLP} y \texttt{coPapersCiteseer}. %El grafo \texttt{snap-amazon} posee más de un millón de cliques y es el menos clusterizado de los ocho grafos, lo que se traduce en 
%solo para los grafos pequeños \texttt{marknewman-astro} y \texttt{marknewman-condmat} se obtienen resultados mejores con respecto a WebGraph, en ambos casos casi la mitad. Pero en general, tampoco se logra un tiempo mejor a los algoritmos en comparación, y para los grafos \texttt{coPapersDBLP} y \texttt{coPapersCiteseer} que presentan la mejor compresión, se obtienen tiempos mucho más altos (ver Tabla~\ref{table:timesSecuencial}).

\textcolor{red}{Quiero profundizar más sobre el resultado de los tiempos de acceso y reconstrucción, además de agregar la ventaja de recuperar cliques maximales y poder consultar vecindad de dos nodos, ambas consultas que solo tiene implementadas este método.}

Con esto en consideración, una buena aplicación para el método propuesto son dispositivos donde el espacio para guardar el grafo sea limitado, como dispositivos móviles con poca RAM y espacio en disco, donde se pueden almacenar los grafos usando una compresión muy eficiente, y que permitirá responder consultas sin ocupar mucho espacio extra y en un tiempo algo mayor. Esto no es menor, ya que sin esta opción de compresión, y pese a su costo en tiempos de acceso, no se podría almacenar los grafos en dichos dispositivos de otra manera.

Además, esta estructura compacta permite obtener el listado de cliques maximales directamente de ella, sin tener que descomprimir el grafo completo, y pese a que se necesita generar este listado antes de su construcción, una vez comprimido permite listar los cliques de manera rápida (ver Tabla~\ref{table:constructTimes}). Esto, junto con el nivel de compresión ya mencionado, sirve para trabajar con dispositivos de memoria acotada en variadas aplicaciones biológicas \cite{eblen2012maximum, hendrix2010theoretical}, entre otras \cite{bomze1999maximum}.


Como trabajo futuro, se puede explorar cómo mejorar los tiempos de acceso de esta estructura, por ejemplo investigar nuevas funciones de ranking en la heurística de clusterización. Otra opción es explotar el potencial de paralelismo que posee la estructura compacta, ya que cada partición se puede acceder de manera simultánea, y cada comparación de bytes dentro de las particiones se puede optimizar usando instrucciones paralelas como SIMD\footnote{SIMD: Single Instruction, Multiple Data. Una Instrucción, múltiples datos.}.


